{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 5 (бонусная): экспериментальное исследование алгоритмов для регулярных запросов #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yk54_Ej32Bt"
   },
   "source": [
    "## Подготовка окружения ##\n",
    "\n",
    "Note: Linux only\n",
    "\n",
    "Установка необходимых зависимостей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YK4kVHI-13X8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: antlr4-python3-runtime in /home/vladi/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (4.11.1)\n",
      "Requirement already satisfied: black in /home/vladi/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (22.6.0)\n",
      "Requirement already satisfied: cfpq-data in /home/vladi/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (4.0.0)\n",
      "Requirement already satisfied: networkx in /home/vladi/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (2.6.2)\n",
      "Requirement already satisfied: pre-commit in /home/vladi/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (2.20.0)\n",
      "Requirement already satisfied: pydot in /home/vladi/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (1.4.2)\n",
      "Requirement already satisfied: pyformlang in /home/vladi/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (0.1.26)\n",
      "Requirement already satisfied: pytest in /home/vladi/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (7.1.2)\n",
      "Requirement already satisfied: scipy in /home/vladi/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (1.9.1)\n",
      "Requirement already satisfied: platformdirs>=2 in /home/vladi/anaconda3/lib/python3.9/site-packages (from black->-r requirements.txt (line 2)) (2.5.2)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /home/vladi/anaconda3/lib/python3.9/site-packages (from black->-r requirements.txt (line 2)) (4.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /home/vladi/anaconda3/lib/python3.9/site-packages (from black->-r requirements.txt (line 2)) (0.4.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/vladi/anaconda3/lib/python3.9/site-packages (from black->-r requirements.txt (line 2)) (8.0.4)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /home/vladi/anaconda3/lib/python3.9/site-packages (from black->-r requirements.txt (line 2)) (0.9.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /home/vladi/anaconda3/lib/python3.9/site-packages (from black->-r requirements.txt (line 2)) (2.0.1)\n",
      "Requirement already satisfied: pandas==1.3.4 in /home/vladi/anaconda3/lib/python3.9/site-packages (from cfpq-data->-r requirements.txt (line 3)) (1.3.4)\n",
      "Requirement already satisfied: rdflib==6.0.0 in /home/vladi/anaconda3/lib/python3.9/site-packages (from cfpq-data->-r requirements.txt (line 3)) (6.0.0)\n",
      "Requirement already satisfied: requests==2.26.0 in /home/vladi/anaconda3/lib/python3.9/site-packages (from cfpq-data->-r requirements.txt (line 3)) (2.26.0)\n",
      "Requirement already satisfied: numpy in /home/vladi/anaconda3/lib/python3.9/site-packages (from pyformlang->-r requirements.txt (line 7)) (1.21.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/vladi/anaconda3/lib/python3.9/site-packages (from pandas==1.3.4->cfpq-data->-r requirements.txt (line 3)) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/vladi/anaconda3/lib/python3.9/site-packages (from pandas==1.3.4->cfpq-data->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: setuptools in /home/vladi/anaconda3/lib/python3.9/site-packages (from rdflib==6.0.0->cfpq-data->-r requirements.txt (line 3)) (63.4.1)\n",
      "Requirement already satisfied: isodate in /home/vladi/anaconda3/lib/python3.9/site-packages (from rdflib==6.0.0->cfpq-data->-r requirements.txt (line 3)) (0.6.1)\n",
      "Requirement already satisfied: pyparsing in /home/vladi/anaconda3/lib/python3.9/site-packages (from rdflib==6.0.0->cfpq-data->-r requirements.txt (line 3)) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/vladi/anaconda3/lib/python3.9/site-packages (from requests==2.26.0->cfpq-data->-r requirements.txt (line 3)) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vladi/anaconda3/lib/python3.9/site-packages (from requests==2.26.0->cfpq-data->-r requirements.txt (line 3)) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vladi/anaconda3/lib/python3.9/site-packages (from requests==2.26.0->cfpq-data->-r requirements.txt (line 3)) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/vladi/anaconda3/lib/python3.9/site-packages (from requests==2.26.0->cfpq-data->-r requirements.txt (line 3)) (2.0.4)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /home/vladi/anaconda3/lib/python3.9/site-packages (from pre-commit->-r requirements.txt (line 5)) (3.3.1)\n",
      "Requirement already satisfied: identify>=1.0.0 in /home/vladi/anaconda3/lib/python3.9/site-packages (from pre-commit->-r requirements.txt (line 5)) (2.5.6)\n",
      "Requirement already satisfied: virtualenv>=20.0.8 in /home/vladi/anaconda3/lib/python3.9/site-packages (from pre-commit->-r requirements.txt (line 5)) (20.16.5)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /home/vladi/anaconda3/lib/python3.9/site-packages (from pre-commit->-r requirements.txt (line 5)) (1.7.0)\n",
      "Requirement already satisfied: toml in /home/vladi/anaconda3/lib/python3.9/site-packages (from pre-commit->-r requirements.txt (line 5)) (0.10.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/vladi/anaconda3/lib/python3.9/site-packages (from pre-commit->-r requirements.txt (line 5)) (6.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/vladi/anaconda3/lib/python3.9/site-packages (from pytest->-r requirements.txt (line 8)) (21.4.0)\n",
      "Requirement already satisfied: iniconfig in /home/vladi/anaconda3/lib/python3.9/site-packages (from pytest->-r requirements.txt (line 8)) (1.1.1)\n",
      "Requirement already satisfied: packaging in /home/vladi/anaconda3/lib/python3.9/site-packages (from pytest->-r requirements.txt (line 8)) (21.3)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /home/vladi/anaconda3/lib/python3.9/site-packages (from pytest->-r requirements.txt (line 8)) (1.0.0)\n",
      "Requirement already satisfied: py>=1.8.2 in /home/vladi/anaconda3/lib/python3.9/site-packages (from pytest->-r requirements.txt (line 8)) (1.11.0)\n",
      "Requirement already satisfied: filelock<4,>=3.4.1 in /home/vladi/anaconda3/lib/python3.9/site-packages (from virtualenv>=20.0.8->pre-commit->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.5 in /home/vladi/anaconda3/lib/python3.9/site-packages (from virtualenv>=20.0.8->pre-commit->-r requirements.txt (line 5)) (0.3.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/vladi/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas==1.3.4->cfpq-data->-r requirements.txt (line 3)) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycubool in /home/vladi/anaconda3/lib/python3.9/site-packages (1.2.0)\n",
      "Requirement already satisfied: matplotlib in /home/vladi/anaconda3/lib/python3.9/site-packages (3.5.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/vladi/anaconda3/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/vladi/anaconda3/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/vladi/anaconda3/lib/python3.9/site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vladi/anaconda3/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/vladi/anaconda3/lib/python3.9/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/vladi/anaconda3/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/vladi/anaconda3/lib/python3.9/site-packages (from matplotlib) (1.21.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/vladi/anaconda3/lib/python3.9/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/vladi/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pycubool matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HngcVASm4LCH"
   },
   "source": [
    "## Введение \n",
    "В эксперименте рассматривается задача достижимости в графе с регулярными ограничениями. Используем библиотеки для работы с разреженными матрицами [scipy.sparse](https://github.com/scipy/scipy) и [pycubool](https://github.com/JetBrains-Research/cuBool) для исследования производительности решений.\n",
    "\n",
    "### О задаче достижимости \n",
    "Пусть дан конечный ориентированный помеченный граф $G = (V, E, L)$. Каждому пути $\\pi \\in E^*$, состоящему из рёбер с метками $l_1, ..., l_n \\in L$, сопоставляется слово по правилу $\\omega(\\pi) = l_1 + ... + l_n$, где $+$ --- конкатенация.\n",
    "\n",
    "Возьмем $R$ --- регулярное выражение.\n",
    "\n",
    "Рассмотрим следующие варианты:\n",
    "\n",
    "#### 1. Достижимость между всеми парами вершин\n",
    "Необходимо найти пары вершин $G$, такие, что между ними существует путь, которому сопоставляется слово из языка, задаваемого $R$. \n",
    "Далее обозначим $V_S$ множество стартовых вершин, $V_F$ множество финальных вершин. \n",
    "\n",
    "#### 2. Достижимость для всего множества заданных вершин\n",
    "\n",
    "Необходимо найти все финальные вершины, такие, что до них существуют пути из стартовых, которым сопоставляются слова из языка, задаваемого $R$.\n",
    "\n",
    "#### 3. Достижимость для каждой вершины из заданного множества стартовых вершин\n",
    "\n",
    "Необходимо найти множество пар вершин-начал и вершин-концов путей, которым сопоставляются слова из языка, задаваемого $R$ \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EsyfZQF9oS2"
   },
   "source": [
    "## Исследуемые решения ##\n",
    "\n",
    "Рассмотрим краткие идеи решения каждой задачи:\n",
    "\n",
    "#### 1. Достижимость между всеми парами вершин\n",
    "По графу и регулярному выражению строятся конечные автоматы, представленные в виде разреженных булевых матриц, а затем ищется их пересечение с помощью тензорного произведения. Финальном шагом является подсчет транзитивного замыкания пересечения автоматов.\n",
    "\n",
    "#### 2. Достижимость для всего множества заданных вершин ####\n",
    "Аналогично по графу и регулярному выражению строятся конечные автоматы, а затем производится синхронный поиск в ширину с помощью матричного произведения.\n",
    "\n",
    "#### 3. Достижимость для каждой вершины из заданного множества стартовых вершин ####\n",
    "Аналогично задаче 2, однако матрица, отражающая в каких состояниях мы находимся на текущей итерации поиска в ширину имеет расширенный вид, так как необходимо поддерживать информацию для каждой стартовой вершины графа отдельно.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FO4YQ-Yz_Kg8"
   },
   "source": [
    "## Реализация\n",
    "\n",
    "Представленные реализации алгоритмов с помощью библиотек **scipy.sparse** и **pycubool** идентичны. \n",
    "\n",
    "На основе **scipy.sparse** представлена в модуле `project.rpq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YTautIrD-Hfd"
   },
   "outputs": [],
   "source": [
    "from project.rpq import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PkTJAG_wCtWL"
   },
   "source": [
    "На основе **pycubool**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vUpz_x14CwVd"
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Set, Any, List\n",
    "\n",
    "from pyformlang.finite_automaton import State, EpsilonNFA\n",
    "\n",
    "from pycubool import Matrix\n",
    "\n",
    "\n",
    "class BoolMatrixAutomatonPyCuBool:\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_to_idx: Dict[State, int],\n",
    "        start_states: Set[State],\n",
    "        final_states: Set[State],\n",
    "        b_mtx: Dict[Any, Matrix],\n",
    "    ):\n",
    "        self.state_to_idx = state_to_idx\n",
    "        self.start_states = start_states\n",
    "        self.final_states = final_states\n",
    "        self.b_mtx = b_mtx\n",
    "\n",
    "    def __and__(\n",
    "        self, other: \"BoolMatrixAutomatonPyCuBool\"\n",
    "    ) -> \"BoolMatrixAutomatonPyCuBool\":\n",
    "        \n",
    "        inter_labels = self.b_mtx.keys() & other.b_mtx.keys()\n",
    "        inter_b_mtx = {\n",
    "            label: self.b_mtx[label].kronecker(other.b_mtx[label])\n",
    "            for label in inter_labels\n",
    "        }\n",
    "        inter_state_to_idx = dict()\n",
    "        inter_start_states = set()\n",
    "        inter_final_states = set()\n",
    "        for self_state, self_idx in self.state_to_idx.items():\n",
    "            for other_state, other_idx in other.state_to_idx.items():\n",
    "                state = State((self_state.value, other_state.value))\n",
    "                idx = self_idx * len(other.state_to_idx) + other_idx\n",
    "                inter_state_to_idx[state] = idx\n",
    "                if (\n",
    "                    self_state in self.start_states\n",
    "                    and other_state in other.start_states\n",
    "                ):\n",
    "                    inter_start_states.add(state)\n",
    "                if (\n",
    "                    self_state in self.final_states\n",
    "                    and other_state in other.final_states\n",
    "                ):\n",
    "                    inter_final_states.add(state)\n",
    "        return BoolMatrixAutomatonPyCuBool(\n",
    "            state_to_idx=inter_state_to_idx,\n",
    "            start_states=inter_start_states,\n",
    "            final_states=inter_final_states,\n",
    "            b_mtx=inter_b_mtx,\n",
    "        )\n",
    "\n",
    "    def transitive_closure(self) -> Matrix:\n",
    "\n",
    "        state_count = max(len(self.state_to_idx), 1)\n",
    "        transitive_closure = Matrix.empty((state_count, state_count))\n",
    "        for b_mtx in self.b_mtx.values():\n",
    "            transitive_closure = transitive_closure.ewiseadd(b_mtx)\n",
    "\n",
    "        prev_nnz, cur_nnz = None, transitive_closure.nvals\n",
    "        if not cur_nnz:\n",
    "            return transitive_closure\n",
    "\n",
    "        while prev_nnz != cur_nnz:\n",
    "            transitive_closure.mxm(\n",
    "                transitive_closure, out=transitive_closure, accumulate=True\n",
    "            )\n",
    "            prev_nnz, cur_nnz = cur_nnz, transitive_closure.nvals\n",
    "        return transitive_closure\n",
    "\n",
    "    @classmethod\n",
    "    def from_nfa(cls, nfa: EpsilonNFA) -> \"BoolMatrixAutomatonPyCuBool\":\n",
    "\n",
    "        state_to_idx = {state: idx for idx, state in enumerate(nfa.states)}\n",
    "        return cls(\n",
    "            state_to_idx=state_to_idx,\n",
    "            start_states=nfa.start_states.copy(),\n",
    "            final_states=nfa.final_states.copy(),\n",
    "            b_mtx=cls._b_mtx_from_nfa(\n",
    "                nfa=nfa,\n",
    "                state_to_idx=state_to_idx,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _b_mtx_from_nfa(\n",
    "        nfa: EpsilonNFA, state_to_idx: Dict[State, int]\n",
    "    ) -> Dict[Any, Matrix]:\n",
    "\n",
    "        b_mtx = dict()\n",
    "        state_from_to_transitions = nfa.to_dict()\n",
    "        for label in nfa.symbols:\n",
    "            mtx = Matrix.empty((len(nfa.states), len(nfa.states)))\n",
    "            for state_from, transitions in state_from_to_transitions.items():\n",
    "                states_to = transitions.get(label, set())\n",
    "                if not isinstance(states_to, set):\n",
    "                    states_to = {states_to}\n",
    "                for state_to in states_to:\n",
    "                    mtx[state_to_idx[state_from], state_to_idx[state_to]] = True\n",
    "            b_mtx[label] = mtx\n",
    "        return b_mtx\n",
    "\n",
    "    def _direct_sum(\n",
    "        self, other: \"BoolMatrixAutomatonPyCuBool\"\n",
    "    ) -> \"BoolMatrixAutomatonPyCuBool\":\n",
    "\n",
    "        shifted_state_to_idx = {\n",
    "            state: len(self.state_to_idx) + idx\n",
    "            for state, idx in other.state_to_idx.items()\n",
    "        }\n",
    "        state_to_idx = {**self.state_to_idx, **shifted_state_to_idx}\n",
    "        start_states = self.start_states | other.start_states\n",
    "        final_states = self.final_states | other.final_states\n",
    "        b_mtx = dict()\n",
    "        for label in self.b_mtx.keys() & other.b_mtx.keys():\n",
    "            mtx = Matrix.empty((len(state_to_idx), len(state_to_idx)))\n",
    "            for i, j in self.b_mtx[label]:\n",
    "                mtx[i, j] = True\n",
    "            for i, j in other.b_mtx[label]:\n",
    "                mtx[len(self.state_to_idx) + i, len(self.state_to_idx) + j] = True\n",
    "            b_mtx[label] = mtx\n",
    "        return BoolMatrixAutomatonPyCuBool(\n",
    "            state_to_idx=state_to_idx,\n",
    "            start_states=start_states,\n",
    "            final_states=final_states,\n",
    "            b_mtx=b_mtx,\n",
    "        )\n",
    "\n",
    "    def sync_bfs(\n",
    "        self,\n",
    "        other: \"BoolMatrixAutomatonPyCuBool\",\n",
    "        reachable_per_node: bool,\n",
    "    ) -> Set[Any]:\n",
    "\n",
    "        if not self.state_to_idx or not other.state_to_idx:\n",
    "            return set()\n",
    "\n",
    "        ordered_start_states = list(self.start_states)\n",
    "\n",
    "        direct_sum = other._direct_sum(self)\n",
    "        initial_front = self._init_sync_bfs_front(\n",
    "            other=other,\n",
    "            reachable_per_node=reachable_per_node,\n",
    "            ordered_start_states=ordered_start_states,\n",
    "        )\n",
    "\n",
    "        front = self._copy_mtx(initial_front)\n",
    "        visited = self._copy_mtx(front)\n",
    "\n",
    "        other_states_num = len(other.state_to_idx)\n",
    "\n",
    "        while True:\n",
    "            visited_nnz = visited.nvals\n",
    "            new_front = self._copy_mtx(front)\n",
    "\n",
    "            for _, mtx in direct_sum.b_mtx.items():\n",
    "                product: Matrix = front.mxm(mtx)\n",
    "                new_front_step = Matrix.empty(product.shape)\n",
    "                for i, j in product:\n",
    "                    if j >= other_states_num:\n",
    "                        continue\n",
    "                    row = product[i : i + 1, other_states_num:]\n",
    "                    if not row.nvals:\n",
    "                        continue\n",
    "                    row_shift = i // other_states_num * other_states_num\n",
    "                    new_front_step[row_shift + j, j] = True\n",
    "                    for _, rj in row:\n",
    "                        new_front_step[row_shift + j, other_states_num + rj] = True\n",
    "                new_front = new_front.ewiseadd(new_front_step)\n",
    "\n",
    "            new_front_without_visited = Matrix.empty(new_front.shape)\n",
    "            for i, j in set(new_front.to_list()).difference(set(visited.to_list())):\n",
    "              new_front_without_visited[i, j] = True\n",
    "\n",
    "            visited = visited.ewiseadd(new_front_without_visited)\n",
    "            front = new_front_without_visited\n",
    "\n",
    "            if visited_nnz == visited.nvals:\n",
    "                break\n",
    "\n",
    "        self_idx_to_state = {idx: state for state, idx in self.state_to_idx.items()}\n",
    "        other_idx_to_state = {idx: state for state, idx in other.state_to_idx.items()}\n",
    "\n",
    "        result = set()\n",
    "        nonzero = set(visited.to_list()).difference(set(initial_front.to_list()))\n",
    "        for i, j in nonzero:\n",
    "            if (\n",
    "                other_idx_to_state[i % other_states_num] not in other.final_states\n",
    "                or j < other_states_num\n",
    "            ):\n",
    "                continue\n",
    "            self_state = self_idx_to_state[j - other_states_num]\n",
    "            if self_state not in self.final_states:\n",
    "                continue\n",
    "            result.add(\n",
    "                self_state.value\n",
    "                if not reachable_per_node\n",
    "                else (\n",
    "                    ordered_start_states[i // other_states_num].value,\n",
    "                    self_state.value,\n",
    "                )\n",
    "            )\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def _copy_mtx(matrix: Matrix) -> Matrix:\n",
    "        \n",
    "        copy = Matrix.empty(matrix.shape)\n",
    "        for i, j in matrix:\n",
    "            copy[i, j] = True\n",
    "        return copy\n",
    "\n",
    "    def _init_sync_bfs_front(\n",
    "        self,\n",
    "        other: \"BoolMatrixAutomatonPyCuBool\",\n",
    "        reachable_per_node: bool,\n",
    "        ordered_start_states: List[State],\n",
    "    ) -> Matrix:\n",
    "\n",
    "        def front_with_self_start_row(self_start_row: List):\n",
    "            front = Matrix.empty(\n",
    "                (\n",
    "                    len(other.state_to_idx),\n",
    "                    len(self.state_to_idx) + len(other.state_to_idx),\n",
    "                )\n",
    "            )\n",
    "            for state in other.start_states:\n",
    "                idx = other.state_to_idx[state]\n",
    "                front[idx, idx] = True\n",
    "                for i, item in enumerate(self_start_row):\n",
    "                    if item:\n",
    "                        front[idx, len(other.state_to_idx) + i] = item\n",
    "            return front\n",
    "\n",
    "        if not reachable_per_node:\n",
    "            start_indices = set(\n",
    "                self.state_to_idx[state] for state in ordered_start_states\n",
    "            )\n",
    "            return front_with_self_start_row(\n",
    "                [idx in start_indices for idx in range(len(self.state_to_idx))]\n",
    "            )\n",
    "\n",
    "        fronts = [\n",
    "            front_with_self_start_row(\n",
    "                [\n",
    "                    idx == self.state_to_idx[start]\n",
    "                    for idx in range(len(self.state_to_idx))\n",
    "                ]\n",
    "            )\n",
    "            for start in ordered_start_states\n",
    "        ]\n",
    "\n",
    "        mtx = Matrix.empty(\n",
    "            (\n",
    "                len(fronts) * len(other.state_to_idx),\n",
    "                len(other.state_to_idx) + len(self.state_to_idx),\n",
    "            )\n",
    "        )\n",
    "        for front_number, front in enumerate(fronts):\n",
    "            for i, j in front:\n",
    "                mtx[len(other.state_to_idx) * front_number + i, j] = True\n",
    "        return mtx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DjRZElIGC5aO"
   },
   "outputs": [],
   "source": [
    "from typing import Set, Optional, Tuple, Any, Callable\n",
    "\n",
    "from networkx import MultiDiGraph\n",
    "from pyformlang.regular_expression import Regex\n",
    "\n",
    "from project import (\n",
    "    graph_to_epsilon_nfa,\n",
    "    generate_min_dfa_by_regex,\n",
    ")\n",
    "\n",
    "def rpq_tensor_pycubool(\n",
    "    graph: MultiDiGraph,\n",
    "    query: Regex,\n",
    "    start_states: Optional[Set],\n",
    "    final_states: Optional[Set],\n",
    ") -> Set[Tuple[Any, Any]]:\n",
    "    \n",
    "    nfa_bool_mtx = BoolMatrixAutomatonPyCuBool.from_nfa(\n",
    "        graph_to_epsilon_nfa(\n",
    "            graph=graph,\n",
    "            start_states=start_states,\n",
    "            final_states=final_states,\n",
    "        )\n",
    "    )\n",
    "    query_bool_mtx = BoolMatrixAutomatonPyCuBool.from_nfa(\n",
    "        generate_min_dfa_by_regex(regex=query),\n",
    "    )\n",
    "    intersection_bool_mtx = nfa_bool_mtx & query_bool_mtx\n",
    "    idx_to_state = {\n",
    "        idx: state for state, idx in intersection_bool_mtx.state_to_idx.items()\n",
    "    }\n",
    "    transitive_closure = intersection_bool_mtx.transitive_closure()\n",
    "    result = set()\n",
    "    for state_from_idx, state_to_idx in transitive_closure:\n",
    "        state_from, state_to = idx_to_state[state_from_idx], idx_to_state[state_to_idx]\n",
    "        if (\n",
    "            state_from in intersection_bool_mtx.start_states\n",
    "            and state_to in intersection_bool_mtx.final_states\n",
    "        ):\n",
    "            state_from_graph_value, _ = state_from.value\n",
    "            state_to_graph_value, _ = state_to.value\n",
    "            result.add(\n",
    "                (state_from_graph_value, state_to_graph_value),\n",
    "            )\n",
    "    return result\n",
    "\n",
    "\n",
    "def rpq_bfs_pycubool(\n",
    "    graph: MultiDiGraph,\n",
    "    query: Regex,\n",
    "    start_states: Optional[Set],\n",
    "    final_states: Optional[Set],\n",
    "    mode: RpqMode,\n",
    ") -> Set[Any]:\n",
    "\n",
    "    nfa_bool_mtx = BoolMatrixAutomatonPyCuBool.from_nfa(\n",
    "        graph_to_epsilon_nfa(\n",
    "            graph=graph,\n",
    "            start_states=start_states,\n",
    "            final_states=final_states,\n",
    "        )\n",
    "    )\n",
    "    query_bool_mtx = BoolMatrixAutomatonPyCuBool.from_nfa(\n",
    "        generate_min_dfa_by_regex(regex=query),\n",
    "    )\n",
    "    return nfa_bool_mtx.sync_bfs(\n",
    "        other=query_bool_mtx,\n",
    "        reachable_per_node=mode\n",
    "        == RpqMode.FIND_REACHABLE_FOR_EACH_START_NODE,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5D9uVr1HCHf"
   },
   "source": [
    "## Цель работы ##\n",
    "\n",
    "В качестве цели работы необходимо найти ответы на следующие вопросы:\n",
    "\n",
    "* Когда использование специализированных библиотек разреженной линейной алгебры даёт выигрыш в производительности? На примере каждой из трех задач.\n",
    "* Если использовать специализированные библиотеки, то начиная с какого размера стартового множества выгоднее решать задачу для всех пар и выбирать нужные?\n",
    "* Если использовать специализированные библиотеки, то на сколько решение второй задачи медленнее решения третьей при одинаковых начальных условиях? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UN60nNpvN4rL"
   },
   "source": [
    "## Условия эксперимента ##\n",
    "\n",
    "Данный раздел посвящен описанию характеристик оборудования, на котором производителись замеры\n",
    "\n",
    "### Характеристики оборудования ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EqiDK5FiOGt7",
    "outputId": "e61980ff-2c7e-4efa-9ff0-8615e1c65625"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== OS  ==========\n",
      "No LSB modules are available.\n",
      "Distributor ID:\tUbuntu\n",
      "Description:\tUbuntu 20.04.5 LTS\n",
      "Release:\t20.04\n",
      "Codename:\tfocal\n",
      "\n",
      "========== CPU ==========\n",
      "Architecture:                    x86_64\n",
      "CPU op-mode(s):                  32-bit, 64-bit\n",
      "Byte Order:                      Little Endian\n",
      "Address sizes:                   48 bits physical, 48 bits virtual\n",
      "CPU(s):                          12\n",
      "On-line CPU(s) list:             0-11\n",
      "Thread(s) per core:              2\n",
      "Core(s) per socket:              6\n",
      "Socket(s):                       1\n",
      "Vendor ID:                       AuthenticAMD\n",
      "CPU family:                      23\n",
      "Model:                           104\n",
      "Model name:                      AMD Ryzen 5 5500U with Radeon Graphics\n",
      "Stepping:                        1\n",
      "CPU MHz:                         2095.989\n",
      "BogoMIPS:                        4191.97\n",
      "Virtualization:                  AMD-V\n",
      "Hypervisor vendor:               Microsoft\n",
      "Virtualization type:             full\n",
      "L1d cache:                       192 KiB\n",
      "L1i cache:                       192 KiB\n",
      "L2 cache:                        3 MiB\n",
      "L3 cache:                        4 MiB\n",
      "Vulnerability Itlb multihit:     Not affected\n",
      "Vulnerability L1tf:              Not affected\n",
      "Vulnerability Mds:               Not affected\n",
      "Vulnerability Meltdown:          Not affected\n",
      "Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled v\n",
      "                                 ia prctl and seccomp\n",
      "Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user\n",
      "                                  pointer sanitization\n",
      "Vulnerability Spectre v2:        Mitigation; Full AMD retpoline, IBPB conditiona\n",
      "                                 l, IBRS_FW, STIBP conditional, RSB filling\n",
      "Vulnerability Srbds:             Not affected\n",
      "Vulnerability Tsx async abort:   Not affected\n",
      "Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtr\n",
      "                                 r pge mca cmov pat pse36 clflush mmx fxsr sse s\n",
      "                                 se2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtsc\n",
      "                                 p lm constant_tsc rep_good nopl tsc_reliable no\n",
      "                                 nstop_tsc cpuid extd_apicid pni pclmulqdq ssse3\n",
      "                                  fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave \n",
      "                                 avx f16c rdrand hypervisor lahf_lm cmp_legacy s\n",
      "                                 vm cr8_legacy abm sse4a misalignsse 3dnowprefet\n",
      "                                 ch osvw topoext ssbd ibrs ibpb stibp vmmcall fs\n",
      "                                 gsbase bmi1 avx2 smep bmi2 rdseed adx smap clfl\n",
      "                                 ushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsav\n",
      "                                 es clzero xsaveerptr arat npt nrip_save tsc_sca\n",
      "                                 le vmcb_clean flushbyasid decodeassists pausefi\n",
      "                                 lter pfthreshold v_vmsave_vmload umip rdpid\n",
      "\n",
      "========== RAM ==========\n",
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:           7627         856        5303           0        1467        6477\n",
      "Swap:          2048           0        2048\n"
     ]
    }
   ],
   "source": [
    "!printf '========== OS  ==========\\n'\n",
    "!lsb_release -a\n",
    "\n",
    "!printf '\\n========== CPU ==========\\n'\n",
    "!lscpu\n",
    "\n",
    "!printf '\\n========== RAM ==========\\n'\n",
    "!free -m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKZBt-UQP2Ap"
   },
   "source": [
    "### Описание используемых данных ###\n",
    "\n",
    "Здесь приведено описание используемых графов и запросов к ним\n",
    "\n",
    "#### Используемые графы ####\n",
    "Эксперимент проводился на девяти графах из датасета [CPFQ-data](https://jetbrains-research.github.io/CFPQ_Data/dataset/index.html): `pizza`, `skos`, `travel`, `atom`, `bzip`, `pr`, `ls`, `gzip`, `funding`. Графы с большим числом вершин не были взяты из-за медленных замеров на личном оборудовании.\n",
    "\n",
    "Загрузка графов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "yDOwmxBJRX32",
    "outputId": "fc442c67-7129-4109-bd05-4f2485984cb7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-10-19 23:51:26]>INFO>Found graph with name='pizza'\n",
      "[2022-10-19 23:51:26]>INFO>Load archive graph_archive=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/pizza.tar.gz')\n",
      "[2022-10-19 23:51:26]>INFO>Unzip graph name='pizza' to file graph=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/pizza/pizza.csv')\n",
      "[2022-10-19 23:51:26]>INFO>Remove archive graph_archive=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/pizza.tar.gz')\n",
      "[2022-10-19 23:51:26]>INFO>Load graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35ca250> from path=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/pizza/pizza.csv')\n",
      "[2022-10-19 23:51:26]>INFO>Found graph with name='skos'\n",
      "[2022-10-19 23:51:27]>INFO>Load archive graph_archive=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/skos.tar.gz')\n",
      "[2022-10-19 23:51:27]>INFO>Unzip graph name='skos' to file graph=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/skos/skos.csv')\n",
      "[2022-10-19 23:51:27]>INFO>Remove archive graph_archive=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/skos.tar.gz')\n",
      "[2022-10-19 23:51:27]>INFO>Load graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c9e80> from path=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/skos/skos.csv')\n",
      "[2022-10-19 23:51:27]>INFO>Found graph with name='travel'\n",
      "[2022-10-19 23:51:27]>INFO>Load archive graph_archive=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/travel.tar.gz')\n",
      "[2022-10-19 23:51:27]>INFO>Unzip graph name='travel' to file graph=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/travel/travel.csv')\n",
      "[2022-10-19 23:51:27]>INFO>Remove archive graph_archive=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/travel.tar.gz')\n",
      "[2022-10-19 23:51:27]>INFO>Load graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3277c10> from path=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/travel/travel.csv')\n",
      "[2022-10-19 23:51:27]>INFO>Found graph with name='atom'\n",
      "[2022-10-19 23:51:27]>INFO>Load archive graph_archive=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/atom.tar.gz')\n",
      "[2022-10-19 23:51:27]>INFO>Unzip graph name='atom' to file graph=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/atom/atom.csv')\n",
      "[2022-10-19 23:51:27]>INFO>Remove archive graph_archive=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/atom.tar.gz')\n",
      "[2022-10-19 23:51:27]>INFO>Load graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01909d0> from path=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/atom/atom.csv')\n",
      "[2022-10-19 23:51:27]>INFO>Found graph with name='bzip'\n",
      "[2022-10-19 23:51:27]>INFO>Load archive graph_archive=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/bzip.tar.gz')\n",
      "[2022-10-19 23:51:27]>INFO>Unzip graph name='bzip' to file graph=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/bzip/bzip.csv')\n",
      "[2022-10-19 23:51:27]>INFO>Remove archive graph_archive=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/bzip.tar.gz')\n",
      "[2022-10-19 23:51:27]>INFO>Load graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35c4910> from path=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/bzip/bzip.csv')\n",
      "[2022-10-19 23:51:27]>INFO>Found graph with name='pr'\n",
      "[2022-10-19 23:51:27]>INFO>Load archive graph_archive=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/pr.tar.gz')\n",
      "[2022-10-19 23:51:27]>INFO>Unzip graph name='pr' to file graph=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/pr/pr.csv')\n",
      "[2022-10-19 23:51:27]>INFO>Remove archive graph_archive=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/pr.tar.gz')\n",
      "[2022-10-19 23:51:27]>INFO>Load graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> from path=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/pr/pr.csv')\n",
      "[2022-10-19 23:51:27]>INFO>Found graph with name='ls'\n",
      "[2022-10-19 23:51:27]>INFO>Load archive graph_archive=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/ls.tar.gz')\n",
      "[2022-10-19 23:51:27]>INFO>Unzip graph name='ls' to file graph=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/ls/ls.csv')\n",
      "[2022-10-19 23:51:27]>INFO>Remove archive graph_archive=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/ls.tar.gz')\n",
      "[2022-10-19 23:51:27]>INFO>Load graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> from path=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/ls/ls.csv')\n",
      "[2022-10-19 23:51:27]>INFO>Found graph with name='gzip'\n",
      "[2022-10-19 23:51:27]>INFO>Load archive graph_archive=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/gzip.tar.gz')\n",
      "[2022-10-19 23:51:27]>INFO>Unzip graph name='gzip' to file graph=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/gzip/gzip.csv')\n",
      "[2022-10-19 23:51:27]>INFO>Remove archive graph_archive=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/gzip.tar.gz')\n",
      "[2022-10-19 23:51:27]>INFO>Load graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> from path=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/gzip/gzip.csv')\n",
      "[2022-10-19 23:51:27]>INFO>Found graph with name='funding'\n",
      "[2022-10-19 23:51:27]>INFO>Load archive graph_archive=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/funding.tar.gz')\n",
      "[2022-10-19 23:51:27]>INFO>Unzip graph name='funding' to file graph=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/funding/funding.csv')\n",
      "[2022-10-19 23:51:27]>INFO>Remove archive graph_archive=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/funding.tar.gz')\n",
      "[2022-10-19 23:51:27]>INFO>Load graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c98e0> from path=PosixPath('/home/vladi/anaconda3/lib/python3.9/site-packages/cfpq_data/data/funding/funding.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Nodes</th>\n",
       "      <th>Edges</th>\n",
       "      <th>Most common labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>skos</td>\n",
       "      <td>144</td>\n",
       "      <td>252</td>\n",
       "      <td>[(type, 70), (label, 32), (definition, 32), (i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>travel</td>\n",
       "      <td>131</td>\n",
       "      <td>277</td>\n",
       "      <td>[(type, 90), (subClassOf, 30), (first, 24), (r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atom</td>\n",
       "      <td>291</td>\n",
       "      <td>425</td>\n",
       "      <td>[(type, 138), (label, 129), (subClassOf, 122),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bzip</td>\n",
       "      <td>632</td>\n",
       "      <td>556</td>\n",
       "      <td>[(d, 297), (a, 259)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pr</td>\n",
       "      <td>815</td>\n",
       "      <td>692</td>\n",
       "      <td>[(d, 359), (a, 333)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>funding</td>\n",
       "      <td>778</td>\n",
       "      <td>1086</td>\n",
       "      <td>[(type, 304), (label, 231), (comment, 229), (s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ls</td>\n",
       "      <td>1687</td>\n",
       "      <td>1453</td>\n",
       "      <td>[(d, 750), (a, 703)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pizza</td>\n",
       "      <td>671</td>\n",
       "      <td>1980</td>\n",
       "      <td>[(disjointWith, 398), (type, 365), (subClassOf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gzip</td>\n",
       "      <td>2687</td>\n",
       "      <td>2293</td>\n",
       "      <td>[(d, 1218), (a, 1075)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Nodes  Edges                                 Most common labels\n",
       "0     skos    144    252  [(type, 70), (label, 32), (definition, 32), (i...\n",
       "1   travel    131    277  [(type, 90), (subClassOf, 30), (first, 24), (r...\n",
       "2     atom    291    425  [(type, 138), (label, 129), (subClassOf, 122),...\n",
       "3     bzip    632    556                               [(d, 297), (a, 259)]\n",
       "4       pr    815    692                               [(d, 359), (a, 333)]\n",
       "5  funding    778   1086  [(type, 304), (label, 231), (comment, 229), (s...\n",
       "6       ls   1687   1453                               [(d, 750), (a, 703)]\n",
       "7    pizza    671   1980  [(disjointWith, 398), (type, 365), (subClassOf...\n",
       "8     gzip   2687   2293                             [(d, 1218), (a, 1075)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cfpq_data\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from project.graph_utils import get_graph_info, load_graph\n",
    "\n",
    "def get_most_common(l, n):\n",
    "    return sorted(Counter(l).most_common(n), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "graph_names = ['pizza', 'skos', 'travel', 'atom', 'bzip', 'pr', 'ls', 'gzip', 'funding']\n",
    "GRAPHS = []\n",
    "stats = []\n",
    "for name in graph_names:\n",
    "  graph = load_graph(name)\n",
    "  graph.name = name\n",
    "  GRAPHS.append(graph)\n",
    "  \n",
    "  info = get_graph_info(graph)\n",
    "  \n",
    "  stats.append([\n",
    "      graph.name,\n",
    "      info.nodes,\n",
    "      info.edges,\n",
    "      get_most_common(map(lambda edge: edge[2], graph.edges(data='label')), 4),\n",
    "  ])\n",
    "    \n",
    "pd.DataFrame(\n",
    "  sorted(stats, key=lambda st: st[2]),\n",
    "  columns=[\"Name\", \"Nodes\", \"Edges\", \"Most common labels\"],\n",
    ")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G25luXMffPVM"
   },
   "source": [
    "#### Используемые регулярные выражения ###\n",
    "\n",
    "Для запросов были выбраны регулярные выражения вида\n",
    "\n",
    "* $(l1|l2)* l3$\n",
    "* $(l1|l2)+ l3*$\n",
    "* $l1 l2 l3 (l4|l1)$\n",
    "* $(l1|l2|l3)*$\n",
    "\n",
    "Если в графе недостаточно уникальных меток, то будем использовать функцию `next_label_if_not_enough` для их предоставления по очереди.\n",
    "\n",
    "Автоматы, представляющие эти выражения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "Hg96YxrThGoD",
    "outputId": "3b1cad92-aa40-47f0-964b-3def5e9b26f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regex</th>\n",
       "      <th>Symbols</th>\n",
       "      <th>States</th>\n",
       "      <th>Transitions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(((a|b))*.c)</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(((a|b).((a|b))*).(c)*)</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(((a.b).c).((d|a))*)</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(((a|b)|c))*</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Regex  Symbols  States  Transitions\n",
       "0             (((a|b))*.c)        3       2            3\n",
       "1  (((a|b).((a|b))*).(c)*)        3       3            6\n",
       "2     (((a.b).c).((d|a))*)        4       4            5\n",
       "3             (((a|b)|c))*        3       1            3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyformlang.regular_expression import Regex\n",
    "from pyformlang.regular_expression.regex_objects import Symbol\n",
    "\n",
    "MAX_LABELS_IN_REGEX = 4\n",
    "REGEXES_STR = [\n",
    "    \"(l1|l2)* l3\",\n",
    "    \"(l1|l2)+ l3*\",\n",
    "    \"l1 l2 l3 (l4|l1)*\",\n",
    "    \"(l1|l2|l3)*\",\n",
    "]\n",
    "\n",
    "def next_label_if_not_enough(labels):\n",
    "    ls = []\n",
    "    for i in range(MAX_LABELS_IN_REGEX):\n",
    "        ls.append(labels[i % len(labels)])\n",
    "    return ls\n",
    "        \n",
    "\n",
    "def label_to_regex(label):\n",
    "  regex = Regex(\"\")\n",
    "  regex.head = Symbol(str(label))\n",
    "  return regex\n",
    "\n",
    "def create_first_regex(labels):\n",
    "  labels = next_label_if_not_enough(labels)\n",
    "  \"\"\"(l1|l2)* l3\"\"\"\n",
    "  r1 = label_to_regex(labels[0])\n",
    "  r2 = label_to_regex(labels[1])\n",
    "  r3 = label_to_regex(labels[2])\n",
    "  return r1.union(r2).kleene_star().concatenate(r3)\n",
    "\n",
    "def create_second_regex(labels):\n",
    "  labels = next_label_if_not_enough(labels)\n",
    "  \"\"\"(l1|l2)+ l3*\"\"\"\n",
    "  r1 = label_to_regex(labels[0]) \n",
    "  r2 = label_to_regex(labels[1])\n",
    "  r3 = label_to_regex(labels[2])\n",
    "  return r1.union(r2).concatenate(r1.union(r2).kleene_star()).concatenate(r3.kleene_star())\n",
    "\n",
    "def create_third_regex(labels):\n",
    "  labels = next_label_if_not_enough(labels)\n",
    "  \"\"\"l1 l2 l3 (l4|l1)*\"\"\"\n",
    "  r1 = label_to_regex(labels[0])\n",
    "  r2 = label_to_regex(labels[1])\n",
    "  r3 = label_to_regex(labels[2])\n",
    "  r4 = label_to_regex(labels[3])\n",
    "  return r1.concatenate(r2).concatenate(r3).concatenate(r4.union(r1).kleene_star())\n",
    "\n",
    "def create_fourth_regex(labels):\n",
    "  labels = next_label_if_not_enough(labels)\n",
    "  \"\"\"(l1|l2|l3)*\"\"\"\n",
    "  r1 = label_to_regex(labels[0])\n",
    "  r2 = label_to_regex(labels[1])\n",
    "  r3 = label_to_regex(labels[2])\n",
    "  return r1.union(r2).union(r3).kleene_star()\n",
    "\n",
    "def create_queries(labels):\n",
    "  return [\n",
    "      create_first_regex(labels),\n",
    "      create_second_regex(labels),\n",
    "      create_third_regex(labels),\n",
    "      create_fourth_regex(labels)\n",
    "  ]\n",
    "\n",
    "def create_queries_by_graph(graph):\n",
    "    most_common_labels = get_most_common(\n",
    "        map(lambda edge: edge[2], graph.edges(data='label')),\n",
    "        MAX_LABELS_IN_REGEX\n",
    "    )\n",
    "    return create_queries(most_common_labels)\n",
    "\n",
    "stats = []\n",
    "for query in create_queries([\"a\", \"b\", \"c\", \"d\"]):\n",
    "    dfa = generate_min_dfa_by_regex(query)\n",
    "    stats.append([\n",
    "        str(query),\n",
    "        len(dfa.symbols),\n",
    "        len(dfa.states),\n",
    "        dfa.get_number_transitions(),\n",
    "    ])\n",
    "\n",
    "pd.DataFrame(stats, columns=[\"Regex\", \"Symbols\", \"States\", \"Transitions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vheYLJhhHq_",
    "outputId": "531e8845-d7d8-402e-d91e-7afa9f504cab"
   },
   "source": [
    "#### Выбор стартовых вершин ###\n",
    "\n",
    "Множества стартовых вершин генерировались при помощи функции generate_multiple_source из библиотеки CFPQ_Data с `seed = 10`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "06VBxe3WveMV"
   },
   "outputs": [],
   "source": [
    "SEED = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_NccMmEXkUG"
   },
   "source": [
    "Определим две величины: \n",
    "* Размер стартового множества, если замеры производятся с фиксированным числом стартовых вершин\n",
    "* Размеры стартовых множеств, если если замеры производятся с различным числом стартовых вершин"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UB-ZwynKXkUH"
   },
   "outputs": [],
   "source": [
    "START_SIZE = 25\n",
    "START_SIZES = [25, 50, 100, 200, 400, 800, 1500, 2000, 2500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LrR0eP0XkUH"
   },
   "source": [
    "## Проводимые замеры ##\n",
    "Рассмотрим, какие замеры необходимо провести, чтобы ответить на поставленные вопросы.\n",
    "\n",
    "* **Вопрос 1**:\n",
    "При каких условиях использование pycubool даёт выигрыш в производительности против использования scipy.sparse? Необходимо определить при каком размере матрицы и степени ее разреженности получается выигрыш. Поэтому следует замерить скорость работы алгоритмов на всевозможных комбинациях выбранных графов и регулярных выражений с фиксированным размером стартового множества.\n",
    "\n",
    "* **Вопрос 2**:\n",
    "При каких размерах множества стартовых вершин, используя pycubool, эффективнее решать задачу в её первой постановке, а при каких в третьей? Поэтому требуется замерить скорость работы данных решений на pycubool на всевозможных комбинациях выбранных графов и регулярных выражений при разных размерах стартового множества вершин. \n",
    "\n",
    "* **Вопрос 3**:\n",
    "Насколько решение задачи на pycubool в её второй постановке быстрее решения в третьей при равных начальных условиях нужно замерить время их работы на одинаковых графах и регулярных запросах с равными стартовыми множествами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRum3PtqXkUH"
   },
   "source": [
    "## Замеры ##\n",
    "Время работы каждого алгоритма на каждый входных данных замерялось пять раз для получения среднего и среднего отклонения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "39qtyYIQXkUH"
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "from statistics import fmean\n",
    "from statistics import stdev\n",
    "import signal\n",
    "from typing import Callable\n",
    "\n",
    "RUN_TIMES = 5\n",
    "\n",
    "\n",
    "class RunTimeoutError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def timeout_handler(_signum, _frame):\n",
    "    raise RunTimeoutError\n",
    "\n",
    "\n",
    "def run_timed(f: Callable, run_times: int, timeout_each_s: int = 600):\n",
    "    timeout_total_s = timeout_each_s * run_times\n",
    "\n",
    "    signal.signal(signal.SIGALRM, timeout_handler)\n",
    "    try:\n",
    "        signal.alarm(timeout_total_s)\n",
    "        times = timeit.repeat(f, repeat=run_times, number=1)\n",
    "    except RunTimeoutError:\n",
    "        times = [float(\"inf\")]\n",
    "    finally:\n",
    "        signal.alarm(0)\n",
    "\n",
    "    mean = fmean(times)\n",
    "    std = stdev(times) if len(times) > 1 else 0\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRpIyjY1XkUI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-10-19 23:51:27]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35ca250> for multiple-source evaluation\n",
      "[2022-10-19 23:51:37]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c9e80> for multiple-source evaluation\n",
      "[2022-10-19 23:51:38]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3277c10> for multiple-source evaluation\n",
      "[2022-10-19 23:51:40]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01909d0> for multiple-source evaluation\n",
      "[2022-10-19 23:51:42]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35c4910> for multiple-source evaluation\n",
      "[2022-10-19 23:51:45]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:51:49]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:51:57]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:52:09]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c98e0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:14]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35ca250> for multiple-source evaluation\n",
      "[2022-10-19 23:52:15]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35ca250> for multiple-source evaluation\n",
      "[2022-10-19 23:52:16]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35ca250> for multiple-source evaluation\n",
      "[2022-10-19 23:52:16]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35ca250> for multiple-source evaluation\n",
      "[2022-10-19 23:52:17]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35ca250> for multiple-source evaluation\n",
      "[2022-10-19 23:52:18]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35ca250> for multiple-source evaluation\n",
      "[2022-10-19 23:52:19]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35ca250> for multiple-source evaluation\n",
      "[2022-10-19 23:52:19]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35ca250> for multiple-source evaluation\n",
      "[2022-10-19 23:52:20]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35ca250> for multiple-source evaluation\n",
      "[2022-10-19 23:52:21]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35ca250> for multiple-source evaluation\n",
      "[2022-10-19 23:52:22]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35ca250> for multiple-source evaluation\n",
      "[2022-10-19 23:52:22]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35ca250> for multiple-source evaluation\n",
      "[2022-10-19 23:52:23]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35ca250> for multiple-source evaluation\n",
      "[2022-10-19 23:52:24]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35ca250> for multiple-source evaluation\n",
      "[2022-10-19 23:52:24]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35ca250> for multiple-source evaluation\n",
      "[2022-10-19 23:52:25]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35ca250> for multiple-source evaluation\n",
      "[2022-10-19 23:52:26]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35ca250> for multiple-source evaluation\n",
      "[2022-10-19 23:52:27]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35ca250> for multiple-source evaluation\n",
      "[2022-10-19 23:52:27]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35ca250> for multiple-source evaluation\n",
      "[2022-10-19 23:52:28]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35ca250> for multiple-source evaluation\n",
      "[2022-10-19 23:52:29]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c9e80> for multiple-source evaluation\n",
      "[2022-10-19 23:52:29]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c9e80> for multiple-source evaluation\n",
      "[2022-10-19 23:52:29]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c9e80> for multiple-source evaluation\n",
      "[2022-10-19 23:52:29]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c9e80> for multiple-source evaluation\n",
      "[2022-10-19 23:52:29]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c9e80> for multiple-source evaluation\n",
      "[2022-10-19 23:52:30]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c9e80> for multiple-source evaluation\n",
      "[2022-10-19 23:52:30]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c9e80> for multiple-source evaluation\n",
      "[2022-10-19 23:52:30]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c9e80> for multiple-source evaluation\n",
      "[2022-10-19 23:52:30]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c9e80> for multiple-source evaluation\n",
      "[2022-10-19 23:52:30]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c9e80> for multiple-source evaluation\n",
      "[2022-10-19 23:52:30]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c9e80> for multiple-source evaluation\n",
      "[2022-10-19 23:52:30]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c9e80> for multiple-source evaluation\n",
      "[2022-10-19 23:52:30]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3277c10> for multiple-source evaluation\n",
      "[2022-10-19 23:52:30]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3277c10> for multiple-source evaluation\n",
      "[2022-10-19 23:52:30]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3277c10> for multiple-source evaluation\n",
      "[2022-10-19 23:52:31]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3277c10> for multiple-source evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-10-19 23:52:31]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3277c10> for multiple-source evaluation\n",
      "[2022-10-19 23:52:31]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3277c10> for multiple-source evaluation\n",
      "[2022-10-19 23:52:31]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3277c10> for multiple-source evaluation\n",
      "[2022-10-19 23:52:31]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3277c10> for multiple-source evaluation\n",
      "[2022-10-19 23:52:31]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3277c10> for multiple-source evaluation\n",
      "[2022-10-19 23:52:31]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3277c10> for multiple-source evaluation\n",
      "[2022-10-19 23:52:31]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3277c10> for multiple-source evaluation\n",
      "[2022-10-19 23:52:32]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3277c10> for multiple-source evaluation\n",
      "[2022-10-19 23:52:32]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01909d0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:32]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01909d0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:32]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01909d0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:32]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01909d0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:33]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01909d0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:33]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01909d0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:33]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01909d0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:33]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01909d0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:33]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01909d0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:34]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01909d0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:34]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01909d0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:34]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01909d0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:34]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01909d0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:34]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01909d0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:34]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01909d0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:35]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01909d0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:35]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35c4910> for multiple-source evaluation\n",
      "[2022-10-19 23:52:35]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35c4910> for multiple-source evaluation\n",
      "[2022-10-19 23:52:35]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35c4910> for multiple-source evaluation\n",
      "[2022-10-19 23:52:36]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35c4910> for multiple-source evaluation\n",
      "[2022-10-19 23:52:36]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35c4910> for multiple-source evaluation\n",
      "[2022-10-19 23:52:37]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35c4910> for multiple-source evaluation\n",
      "[2022-10-19 23:52:37]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35c4910> for multiple-source evaluation\n",
      "[2022-10-19 23:52:37]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35c4910> for multiple-source evaluation\n",
      "[2022-10-19 23:52:38]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35c4910> for multiple-source evaluation\n",
      "[2022-10-19 23:52:38]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35c4910> for multiple-source evaluation\n",
      "[2022-10-19 23:52:39]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35c4910> for multiple-source evaluation\n",
      "[2022-10-19 23:52:39]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35c4910> for multiple-source evaluation\n",
      "[2022-10-19 23:52:39]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35c4910> for multiple-source evaluation\n",
      "[2022-10-19 23:52:40]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35c4910> for multiple-source evaluation\n",
      "[2022-10-19 23:52:40]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35c4910> for multiple-source evaluation\n",
      "[2022-10-19 23:52:41]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35c4910> for multiple-source evaluation\n",
      "[2022-10-19 23:52:41]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35c4910> for multiple-source evaluation\n",
      "[2022-10-19 23:52:41]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35c4910> for multiple-source evaluation\n",
      "[2022-10-19 23:52:42]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35c4910> for multiple-source evaluation\n",
      "[2022-10-19 23:52:42]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff35c4910> for multiple-source evaluation\n",
      "[2022-10-19 23:52:43]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-10-19 23:52:43]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:43]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:44]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:44]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:45]>INFO>Generate set of source vertices of 800 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:46]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:47]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:47]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:47]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:48]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:49]>INFO>Generate set of source vertices of 800 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:50]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:50]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:51]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:51]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:52]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:52]>INFO>Generate set of source vertices of 800 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:54]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:54]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:54]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:55]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:55]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:56]>INFO>Generate set of source vertices of 800 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7faff01177c0> for multiple-source evaluation\n",
      "[2022-10-19 23:52:57]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:52:58]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:52:59]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:52:59]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:00]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:02]>INFO>Generate set of source vertices of 800 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:05]>INFO>Generate set of source vertices of 1500 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:10]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:10]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:11]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:12]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:13]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:14]>INFO>Generate set of source vertices of 800 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:17]>INFO>Generate set of source vertices of 1500 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:22]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:22]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:23]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:24]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:25]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:27]>INFO>Generate set of source vertices of 800 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:29]>INFO>Generate set of source vertices of 1500 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:34]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-10-19 23:53:34]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:35]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:36]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:37]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:39]>INFO>Generate set of source vertices of 800 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:41]>INFO>Generate set of source vertices of 1500 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb3266310> for multiple-source evaluation\n",
      "[2022-10-19 23:53:46]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:53:47]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:53:48]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:53:49]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:53:51]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:53:54]>INFO>Generate set of source vertices of 800 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:53:58]>INFO>Generate set of source vertices of 1500 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:54:05]>INFO>Generate set of source vertices of 2000 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:54:14]>INFO>Generate set of source vertices of 2500 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:54:26]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:54:27]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:54:28]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:54:29]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:54:31]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:54:33]>INFO>Generate set of source vertices of 800 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:54:38]>INFO>Generate set of source vertices of 1500 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:54:45]>INFO>Generate set of source vertices of 2000 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:54:54]>INFO>Generate set of source vertices of 2500 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:55:05]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:55:06]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:55:07]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:55:09]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:55:11]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:55:13]>INFO>Generate set of source vertices of 800 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:55:17]>INFO>Generate set of source vertices of 1500 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:55:25]>INFO>Generate set of source vertices of 2000 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:55:34]>INFO>Generate set of source vertices of 2500 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:55:45]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:55:46]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:55:47]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:55:48]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:55:50]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:55:53]>INFO>Generate set of source vertices of 800 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:55:57]>INFO>Generate set of source vertices of 1500 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:56:04]>INFO>Generate set of source vertices of 2000 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:56:13]>INFO>Generate set of source vertices of 2500 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb325d790> for multiple-source evaluation\n",
      "[2022-10-19 23:56:25]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c98e0> for multiple-source evaluation\n",
      "[2022-10-19 23:56:25]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c98e0> for multiple-source evaluation\n",
      "[2022-10-19 23:56:25]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c98e0> for multiple-source evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-10-19 23:56:26]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c98e0> for multiple-source evaluation\n",
      "[2022-10-19 23:56:27]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c98e0> for multiple-source evaluation\n",
      "[2022-10-19 23:56:28]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c98e0> for multiple-source evaluation\n",
      "[2022-10-19 23:56:28]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c98e0> for multiple-source evaluation\n",
      "[2022-10-19 23:56:29]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c98e0> for multiple-source evaluation\n",
      "[2022-10-19 23:56:29]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c98e0> for multiple-source evaluation\n",
      "[2022-10-19 23:56:30]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c98e0> for multiple-source evaluation\n",
      "[2022-10-19 23:56:31]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c98e0> for multiple-source evaluation\n",
      "[2022-10-19 23:56:31]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c98e0> for multiple-source evaluation\n",
      "[2022-10-19 23:56:31]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c98e0> for multiple-source evaluation\n",
      "[2022-10-19 23:56:32]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c98e0> for multiple-source evaluation\n",
      "[2022-10-19 23:56:32]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c98e0> for multiple-source evaluation\n",
      "[2022-10-19 23:56:33]>INFO>Generate set of source vertices of 25 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c98e0> for multiple-source evaluation\n",
      "[2022-10-19 23:56:34]>INFO>Generate set of source vertices of 50 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c98e0> for multiple-source evaluation\n",
      "[2022-10-19 23:56:34]>INFO>Generate set of source vertices of 100 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c98e0> for multiple-source evaluation\n",
      "[2022-10-19 23:56:34]>INFO>Generate set of source vertices of 200 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c98e0> for multiple-source evaluation\n",
      "[2022-10-19 23:56:35]>INFO>Generate set of source vertices of 400 nodes for graph=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fafb32c98e0> for multiple-source evaluation\n"
     ]
    }
   ],
   "source": [
    "from cfpq_data import *\n",
    "import scipy.sparse\n",
    "\n",
    "def run_fixed_starts():\n",
    "    results = []\n",
    "\n",
    "    for graph in GRAPHS:\n",
    "        regexes = create_queries_by_graph(graph)\n",
    "        starts = cfpq_data.generate_multiple_source(graph, START_SIZE, seed=SEED)\n",
    "\n",
    "        graph_results = []\n",
    "        for regex in regexes:\n",
    "            by_tensor = run_timed(\n",
    "                lambda: rpq_tensor(\n",
    "                    graph,\n",
    "                    regex,\n",
    "                    starts,\n",
    "                    None,\n",
    "                ),\n",
    "                run_times=RUN_TIMES,\n",
    "            )\n",
    "            by_bfs_all = run_timed(\n",
    "                lambda: rpq_bfs(\n",
    "                    graph,\n",
    "                    regex,\n",
    "                    start_states=starts,\n",
    "                    final_states=None,\n",
    "                    mode=RpqMode.FIND_ALL_REACHABLE\n",
    "                ),\n",
    "                run_times=RUN_TIMES,\n",
    "            )\n",
    "            by_bfs_each = run_timed(\n",
    "                lambda: rpq_bfs(\n",
    "                    graph,\n",
    "                    regex,\n",
    "                    start_states=starts,\n",
    "                    final_states=None,\n",
    "                    mode=RpqMode.FIND_REACHABLE_FOR_EACH_START_NODE\n",
    "                ),\n",
    "                run_times=RUN_TIMES,\n",
    "            )\n",
    "            by_tensor_cuda = run_timed(\n",
    "                lambda: rpq_tensor_pycubool(\n",
    "                    graph,\n",
    "                    regex,\n",
    "                    start_states=starts,\n",
    "                    final_states=None,\n",
    "                ),\n",
    "                run_times=RUN_TIMES,\n",
    "            )\n",
    "            by_bfs_all_cuda = run_timed(\n",
    "                lambda: rpq_bfs_pycubool(\n",
    "                    graph,\n",
    "                    regex,\n",
    "                    start_states=starts,\n",
    "                    final_states=None,\n",
    "                    mode=RpqMode.FIND_ALL_REACHABLE\n",
    "                ),\n",
    "                run_times=RUN_TIMES,\n",
    "            )\n",
    "            by_bfs_each_cuda = run_timed(\n",
    "                lambda: rpq_bfs_pycubool(\n",
    "                    graph,\n",
    "                    regex,\n",
    "                    start_states=starts,\n",
    "                    final_states=None,\n",
    "                    mode=RpqMode.FIND_REACHABLE_FOR_EACH_START_NODE\n",
    "                ),\n",
    "                run_times=RUN_TIMES,\n",
    "            )\n",
    "            graph_results.append(\n",
    "                ((by_tensor, by_bfs_all, by_bfs_each), (by_tensor_cuda, by_bfs_all_cuda, by_bfs_each_cuda))\n",
    "            )\n",
    "\n",
    "        results.append(graph_results)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_varied_starts():\n",
    "    results = []\n",
    "\n",
    "    for graph in GRAPHS:\n",
    "        regexes = create_queries_by_graph(graph)\n",
    "        graph_results = []\n",
    "        for regex in regexes:\n",
    "            regex_results = {}\n",
    "            for start_size in START_SIZES:\n",
    "                if start_size > graph.number_of_nodes():\n",
    "                    continue\n",
    "                starts = generate_multiple_source(graph, start_size, seed=SEED)\n",
    "                by_tensor_cuda = run_timed(\n",
    "                    lambda: rpq_tensor_pycubool(\n",
    "                        graph,\n",
    "                        regex,\n",
    "                        start_states=starts,\n",
    "                        final_states=None\n",
    "                    ),\n",
    "                    run_times=RUN_TIMES,\n",
    "                )\n",
    "                by_bfs_each_cuda = run_timed(\n",
    "                    lambda: rpq_bfs_pycubool(\n",
    "                        graph,\n",
    "                        regex,\n",
    "                        start_states=starts,\n",
    "                        final_states=None,\n",
    "                        mode=RpqMode.FIND_REACHABLE_FOR_EACH_START_NODE\n",
    "                    ),\n",
    "                    run_times=RUN_TIMES,\n",
    "                )\n",
    "                regex_results[start_size] = (by_tensor_cuda, by_bfs_each_cuda)\n",
    "            graph_results.append(regex_results)\n",
    "        results.append(graph_results)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "fixed_starts_res = run_fixed_starts()\n",
    "varied_starts_res = run_varied_starts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGiTA9C2XkUI"
   },
   "source": [
    "## Результаты ##\n",
    "\n",
    "В данном разделе приведены полученные графики, а также приведены ответы на поставленные вопросы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goBi-peHkGrm"
   },
   "source": [
    "## Ответы на вопросы ##\n",
    "\n",
    "**При каких условиях использование специализированных библиотек разреженной линейной алгебры даёт выигрыш в производительности? Для каждой из трёх задач.**\n",
    "\n",
    "Из графиков 1.1.1, 1.1.2, 1.1.3 следует, что для постановок 1 и 2 всех графов и для всех запросов, основанное на `pycubool` решение показывает результаты лучше, чем решение, основанное на `scipy.sparse`.\n",
    "Однако на графе `gzip`, при регулярном запросе, который задается первым регулярным выражением, решение на `scipy` показало себя лучше. \n",
    "Как можно заметить из графиков, величина выигрыша практически не зависит от размера графа, однако может зависить от регулярного запроса, что видно на замере работы на графе `gzip` в третьей задаче.\n",
    "\n",
    "**Начиная с какого размера стартового множества выгоднее решать задачу для всех пар и выбирать нужные? (При использовании специализированных библиотек)**\n",
    "\n",
    "Для ответа на этот вопрос рассмотрим график 2. Как можно заметить, для всех выбранных графов эффективнее решать задачу в первой постановке, используя тензорное произведение, и выбирать из всех найденных пар нужные. Причем, при увеличении числа стартовых вершин разрыв во времени увеличивается.\n",
    "\n",
    "\n",
    "**На сколько решение второй задачи медленнее решения третьей при одинаковых начальных условиях? (При использовании специализированных библиотек)**\n",
    "\n",
    "Из графика 3 следует, что для всех графов и для всех регулярных запросов, время выполнения задачи 2 быстрее, чем время выполнения задачи 3. В среднем разница в 2 раза.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWXoLrI8XkUI"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "ALGORITHMS = [\"Tensor\", \"BFS\", \"Separated BFS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XUex6P8qXkUJ",
    "outputId": "a932753f-79be-4b14-cf5f-0ac45ced4ef6"
   },
   "outputs": [],
   "source": [
    "def batch_plots_1(res):\n",
    "    fig_size = (2.5 * len(REGEXES_STR), len(GRAPHS))\n",
    "    label_locations = np.arange(len(REGEXES_STR))\n",
    "    bar_width = 0.25\n",
    "    cap_size = 4\n",
    "\n",
    "    for algo_i, algo_name in enumerate(ALGORITHMS):\n",
    "        fig: plt.Figure\n",
    "        fig, axs = plt.subplots(len(GRAPHS) // 2, 2, figsize=fig_size)\n",
    "\n",
    "        fig.suptitle(\n",
    "            f\"Plot 1.1.{algo_i + 1}. Absolute difference scipy.sparse vs pycubool performance for {algo_name}\")\n",
    "        fig.tight_layout()\n",
    "\n",
    "        for g_i, ax in enumerate(axs.flat):\n",
    "            graph_name = GRAPHS[g_i].name\n",
    "            graph_results = res[g_i]\n",
    "\n",
    "            ax.set_xlabel(graph_name, weight=\"bold\")\n",
    "            ax.xaxis.set_label_position(\"top\")\n",
    "\n",
    "            ax.set_xticks(label_locations, REGEXES_STR)\n",
    "            ax.tick_params(axis='x', which='both', bottom=False)\n",
    "            if not g_i % len(axs[0]):\n",
    "                ax.set_ylabel(\"Time, s\")\n",
    "\n",
    "            scipy_means = [rs[0][algo_i][0] for rs in graph_results]\n",
    "            scipy_stdevs = [rs[0][algo_i][1] for rs in graph_results]\n",
    "            ax.bar(\n",
    "                label_locations - bar_width / 2,\n",
    "                scipy_means,\n",
    "                bar_width,\n",
    "                yerr=scipy_stdevs,\n",
    "                color=\"tab:green\",\n",
    "                label=\"scipy.sparse\",\n",
    "                capsize=cap_size,\n",
    "            )\n",
    "\n",
    "            pycubool_means = [rs[1][algo_i][0] for rs in graph_results]\n",
    "            pycubool_stdevs = [rs[1][algo_i][1] for rs in graph_results]\n",
    "            ax.bar(\n",
    "                label_locations + bar_width / 2,\n",
    "                pycubool_means,\n",
    "                bar_width,\n",
    "                yerr=pycubool_stdevs,\n",
    "                color=\"tab:blue\",\n",
    "                label=\"pycubool\",\n",
    "                capsize=cap_size,\n",
    "            )\n",
    "\n",
    "        handles, labels = axs[-1][-1].get_legend_handles_labels()\n",
    "        fig.legend(handles, labels, bbox_to_anchor=(1, 1), loc=\"upper left\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "batch_plots_1(fixed_starts_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2XiNX92TXkUJ",
    "outputId": "724b32b5-7c5a-4fb5-c7a4-e1622c505da9"
   },
   "outputs": [],
   "source": [
    "def batch_plots_2(res):\n",
    "    fig, axs = plt.subplots(len(GRAPHS), len(REGEXES_STR), figsize=(5 * len(REGEXES_STR), 3 * len(GRAPHS)))\n",
    "\n",
    "    fig.suptitle(\"Plot 2. Start set size influence on algorithm 1 vs algorithm 3\")\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.95)\n",
    "\n",
    "    bar_width = 0.2\n",
    "    cap_size = 4\n",
    "\n",
    "    for g_i, axs_row in enumerate(axs):\n",
    "        graph_name = GRAPHS[g_i].name\n",
    "        graph_results = res[g_i]\n",
    "\n",
    "        for r_i, ax in enumerate(axs_row):\n",
    "            regex_name = list(REGEXES_STR)[r_i]\n",
    "            regex_results = graph_results[r_i]\n",
    "\n",
    "            if not g_i:\n",
    "                ax.set_xlabel(regex_name, weight=\"bold\")\n",
    "                ax.xaxis.set_label_position(\"top\")\n",
    "\n",
    "            if not r_i:\n",
    "                ax.set_ylabel(\"Time, s\")\n",
    "\n",
    "            if r_i == len(REGEXES_STR) - 1:\n",
    "                ax.set_ylabel(graph_name, weight=\"bold\")\n",
    "                ax.yaxis.set_label_position(\"right\")\n",
    "\n",
    "            label_locations = np.arange(len(regex_results))\n",
    "            ax.set_xticks(label_locations, regex_results.keys())\n",
    "\n",
    "            algo1_results = [rs[0] for rs in regex_results.values()]\n",
    "            algo1_means, algo1_stdevs = zip(*algo1_results)\n",
    "            ax.bar(\n",
    "                label_locations - bar_width / 2,\n",
    "                algo1_means,\n",
    "                bar_width,\n",
    "                yerr=algo1_stdevs,\n",
    "                color=\"tab:red\",\n",
    "                label=ALGORITHMS[0],\n",
    "                capsize=cap_size,\n",
    "            )\n",
    "\n",
    "            algo3_results = [rs[1] for rs in regex_results.values()]\n",
    "            algo3_means, algo3_stdevs = zip(*algo3_results)\n",
    "            ax.bar(\n",
    "                label_locations + bar_width / 2,\n",
    "                algo3_means,\n",
    "                bar_width,\n",
    "                yerr=algo3_stdevs,\n",
    "                color=\"tab:purple\",\n",
    "                label=ALGORITHMS[2],\n",
    "                capsize=cap_size,\n",
    "            )\n",
    "\n",
    "            ax.tick_params(axis='x', which='both', bottom=False)\n",
    "\n",
    "    handles, labels = axs[-1][-1].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(1, 1), loc=\"upper left\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "batch_plots_2(varied_starts_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 915
    },
    "id": "DBGWhS-wXkUJ",
    "outputId": "0baafac9-4aa3-447c-a33a-4f2d3a6c2988"
   },
   "outputs": [],
   "source": [
    "def batch_plots_3(res):\n",
    "    fig_size = (2.5 * len(REGEXES_STR), len(GRAPHS))\n",
    "    label_locations = np.arange(len(REGEXES_STR))\n",
    "    bar_width = 0.2\n",
    "    cap_size = 4\n",
    "\n",
    "    fig, axs = plt.subplots(len(GRAPHS) // 2, 2, figsize=fig_size)\n",
    "\n",
    "    fig.suptitle(\"Plot 3. BFS-based algorithms comparison\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    for g_i, ax in enumerate(axs.flat):\n",
    "        graph_name = GRAPHS[g_i].name\n",
    "        graph_results = res[g_i]\n",
    "\n",
    "        ax.set_xlabel(graph_name, weight=\"bold\")\n",
    "        ax.xaxis.set_label_position(\"top\")\n",
    "\n",
    "        ax.set_xticks(label_locations, REGEXES_STR)\n",
    "        ax.tick_params(axis='x', which='both', bottom=False)\n",
    "        if not g_i % len(axs[0]):\n",
    "            ax.set_ylabel(\"Time, s\")\n",
    "\n",
    "        pycubool_algo2_means = [rs[1][1][0] for rs in graph_results]\n",
    "        pycubool_algo2_stdevs = [rs[1][1][1] for rs in graph_results]\n",
    "        ax.bar(\n",
    "            label_locations - bar_width / 2,\n",
    "            pycubool_algo2_means,\n",
    "            bar_width,\n",
    "            yerr=pycubool_algo2_stdevs,\n",
    "            color=\"tab:blue\",\n",
    "            label=ALGORITHMS[1],\n",
    "            capsize=cap_size,\n",
    "        )\n",
    "\n",
    "        pycubool_algo3_means = [rs[1][2][0] for rs in graph_results]\n",
    "        pycubool_algo3_stdevs = [rs[1][2][1] for rs in graph_results]\n",
    "        ax.bar(\n",
    "            label_locations + bar_width / 2,\n",
    "            pycubool_algo3_means,\n",
    "            bar_width,\n",
    "            yerr=pycubool_algo3_stdevs,\n",
    "            color=\"tab:green\",\n",
    "            label=ALGORITHMS[2],\n",
    "            capsize=cap_size,\n",
    "        )\n",
    "\n",
    "    handles, labels = axs[-1][-1].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(1, 1), loc=\"upper left\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "batch_plots_3(fixed_starts_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k6igmIwPXxWb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ofN4mEjhX4kZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
